There are 2 ways to configure a cloud instance - you can pre-build the image via something like packer or you can dynamically configure the image when its allocated via configuration management. The trade-offs are obvious, quickly deploy and scale your infrastructure, or forge the overhead of image catalogs & ci image build chains and just build everything on the fly. Or some combination of the two. cloud-init has always seems to be somewhere in the middle - all the benefits of dynamic allocation without a lot of the overhead of using configuration management agents.

My initial reaction to damn near every problem is write a bash script. My initial reaction is usually wrong. A more robust language like Python or Ruby has a lot more flexibility I hate the overheard of maintaining pips and gems and what not. It seriously offends me installing 50 packages of dependencies on a systems just so your CM can templatize a couple config files and install some binaries. Not to self: learn more Go. Given that none of the IT problems we're solving today are especially new it seems to reason that if you abstract out a problem far enough its already been solved. By a lot of people, many of which who were way smarter than me. So my mantra as of late has become: if I've written more then 20 lines of bash, I've already lost. Most admins rarely invent wheels. More often we are sucking bits an pieces from all over and connecting the dots.

CoreOS leans towards the cloud-init approach. From a high level beautifully simplistic. on your first boot you define & init all the service you want working & by the time your cloud image has booted for the first time its configured and running exactly like you expect. Recently I've been doing Kubernetes on CoreOS on OpenStack builds with Terraform. Its all fairly straight forward, you define your architecture, template out some cloud-init, spin everything up and blammo its done in a remarkably quick manner. In this particular use case there is a problem - you end up with a gigantic cloud-init file with an immense number of parameters and inline scripts and configuration files that just makes me sad. So whats the solution?

Initially I had visions of preloading cloud-drives with

Late one night I came up with an idea. As with many ideas you never really know how well it works until you try it. While looking at Terraform's list of providers I noticed that it supported Consul. Consul does a number of very fun things but one of its functions is as a k/v store with REST API. its primary use case is for small text values, but as noted in the documentation its got a 512k value limit so theres really nothing stopping you from curl'ing any number of large-ish blobs into it.

Since we're already knee deep in Terraform, use that to manage all the instance specific configuration files and init scripts individually. So how about instead of dropping all the config files and init scripts inline into your cloud-init you just write a small connector to just pull them remotely.

idea - on demand file init. hack cloud-init to use a remote store & whenever a file is referenced thats not existing pull it from somwehere. or add a proxy to define where something should come from - i.e. git / kv / binary store, etc.

This Terraform is essentially just coing the instructions found here: <https://coreos.com/kubernetes/docs/latest/getting-started.html>
